# Indian Sign Language â€“ Non-Manual Feature Interpreter (MVP)
A lightweight browser-based system that reads facial expressions, head movements and shoulder posture to generate meaningful ISL cues.

---

## ğŸŒŸ Overview
This project demonstrates a minimal but functional prototype that uses a webcam to capture non-manual features (NMFs) used in Indian Sign Language â€” such as eyebrow movements, mouth openness, nodding, shaking, and head/shoulder tilt â€” and converts them into readable text outputs.

The current version uses **rule-based detection**, while future versions will integrate **machine learning models**.

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Start Local Server
(Mediapipe requires local hosting)

```bash
cd isl-nmf-mvp/web
python3 -m http.server 8000
```

### 2ï¸âƒ£ Open in Browser
Visit:

```
http://localhost:8000
```

Allow webcam permissions.

### 3ï¸âƒ£ Try the Expressions

| Action | Interpretation |
|-------|----------------|
| Raise eyebrows | Question / Emphasis |
| Open mouth | Surprise / Exclamation |
| Tilt head | Curiosity / Doubt |
| Nod up/down | Agreement / Thinking |
| Shake head | No / Disagreement |
| Lean shoulders | Direction / Emphasis |

---

## ğŸ” Features Detected

| Feature | Method Used | Meaning |
|---------|--------------|---------|
| Eyebrow Raise | Browâ€“eye distance | questioning, emphasis |
| Mouth Open | Lip gap | surprise, exclamation |
| Head Tilt | Roll angle | doubt, curiosity |
| Head Nod | Vertical movement | yes, thinking |
| Head Shake | Horizontal movement | no, disagreement |
| Shoulder Lean | Shoulder tilt | emphasis, direction |

All features are extracted using **MediaPipe FaceMesh + Pose landmarks**.

---

## ğŸ§© System Architecture

### Phase A (Current): Rule-Based Layer
- MediaPipe FaceMesh (478 points)
- MediaPipe Pose (33 points)
- Threshold evaluation
- Simple if-else mapping to text

### Phase B (Upcoming): ML Classifier
- Build labeled CSV dataset
- Train a small classifier (LogReg / tiny neural net)
- Export and run in browser with TensorFlow.js

---

## ğŸ“ Folder Structure

```
isl-nmf-mvp/
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ app.js
â”‚   â””â”€â”€ styles.css
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ nmf_training.csv
â”‚
â””â”€â”€ train/
    â””â”€â”€ train_classifier.py
```

---

## ğŸ”§ Landmarks & Thresholds

### Face Mesh Landmarks
- Eyebrows: 70, 300  
- Eyes: 159, 386  
- Mouth: 13, 14  
- Nose: 1, 168  
- Chin: 152  
- Ears: 234, 454  

### Pose Landmarks
- Shoulders: 11, 12  

### Threshold Values

```javascript
eyebrowRaise: avgBrowDist > 0.04;
mouthOpen: mouthHeight > 0.02;
headTilt: Math.abs(angle) > 0.15;
headNod: Math.abs(deltaY) > 0.03;
headShake: Math.abs(horizontalOffset) > 0.05;
shoulderLean: Math.abs(tiltAngle) > 0.2;
```

---

## ğŸ¤– Phase B: ML Pipeline

### 1. Dataset Creation
Sample CSV format:

```csv
eyebrow_raise,mouth_open,head_tilt,head_nod,head_shake,shoulder_lean,label
1,0,0,0,0,0,question
0,1,0,0,0,0,exclamation
0,0,1,0,0,0,curiosity
```

### 2. Enable Logging in `app.js`

```javascript
collectMode = true;
currentLabel = 'surprise';
console.log(JSON.stringify(currentFeatures));
```

### 3. Train Classifier
Run training script:

```
python train/train_classifier.py
```

### 4. Export to TF.js
Load trained model into browser.

---

## ğŸ› ï¸ Customization

### Add New Feature
```javascript
currentFeatures.newFeature = computeFeature(landmarks) > limit ? 1 : 0;
```

### Modify Rules
```javascript
if (features.headTilt === 1) output.push("curiosity");
```

### Adjust Sensitivity
Tune thresholds depending on lighting or camera distance.

---

## ğŸ Troubleshooting

| Issue | Fix |
|-------|------|
| Webcam blocked | Allow permissions, use localhost |
| Laggy detection | Reduce model complexity |
| Wrong detection | Increase thresholds |
| Mediapipe not loading | Check CDN |

---

## ğŸ“Œ Roadmap
- âœ” MVP â€“ Rule based  
- â˜ ML classifier  
- â˜ Regional ISL variants  
- â˜ Mobile (TFLite)  
- â˜ Dataset expansion  
- â˜ Grammar integration  

---

## ğŸ“œ License
MIT License â€” free for research and educational use.

---

**Made for accessible ISL communication. ğŸ¤Ÿ**